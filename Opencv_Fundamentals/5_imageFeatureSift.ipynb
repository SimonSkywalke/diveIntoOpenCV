{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 空间尺度的基本概念\n",
    "\n",
    "### 尺度的定义\n",
    "\n",
    "在图像处理领域，尺度指的是图像中细节的大小或分辨率。不同尺度下，图像的特征表现不同，小尺度下可以看到细节，而大尺度下则可以观察到整体结构。通过在不同尺度上分析图像，可以更全面地理解图像中的信息。\n",
    "\n",
    "### 尺度空间的定义\n",
    "\n",
    "尺度空间是通过在不同尺度下对图像进行处理，生成一系列具有不同分辨率的图像。这些图像共同构成了一个多尺度的表示系统，使得图像特征在不同尺度上得到一致的描述。尺度空间的构建通常使用高斯模糊来实现，因为高斯模糊具有良好的平滑特性和尺度选择性。\n",
    "\n",
    "## 空间尺度的意义\n",
    "\n",
    "### 尺度不变性\n",
    "\n",
    "尺度空间的引入使得图像特征具有尺度不变性。这意味着，无论图像在何种尺度下进行观察，特征点的位置和描述子都保持一致。尺度不变性在图像匹配和目标识别中具有重要作用，因为它可以处理图像的缩放变化。\n",
    "\n",
    "### 多尺度特征分析\n",
    "\n",
    "通过在不同尺度上分析图像，可以检测到不同大小的特征。例如，小尺度下可以检测到细小的边缘和角点，而大尺度下可以检测到大的结构和形状。多尺度特征分析使得算法能够适应各种复杂场景，提取出丰富的图像信息。\n",
    "\n",
    "### 降噪与平滑\n",
    "\n",
    "尺度空间中的大尺度图像通过高斯模糊处理，可以有效地去除图像中的高频噪声，同时保留低频特征。这种降噪和平滑的效果在图像预处理和特征提取中非常有用。\n",
    "\n",
    "## 尺度空间的应用\n",
    "\n",
    "### 边缘检测\n",
    "\n",
    "在不同尺度上进行边缘检测，可以检测到图像中的不同大小的边缘特征。例如，使用 Canny 边缘检测器在不同尺度上进行检测，可以得到多尺度的边缘信息。\n",
    "\n",
    "### 角点检测\n",
    "\n",
    "在不同尺度上进行角点检测，可以检测到图像中的不同大小的角点特征。例如，Harris 角点检测算法可以在不同尺度上进行角点检测，从而实现尺度不变性。\n",
    "\n",
    "### SIFT 算法\n",
    "\n",
    "SIFT 算法通过构建尺度空间，并在尺度空间中检测极值点，来实现尺度不变的特征检测和描述。SIFT 算法的第一步就是构建高斯差分金字塔（DoG 金字塔），用于检测尺度空间中的极值点。\n",
    "\n",
    "### 图像金字塔\n",
    "\n",
    "图像金字塔是尺度空间的一种特殊形式，通过逐层降采样生成不同尺度的图像。图像金字塔在图像压缩、目标检测和图像匹配中有广泛的应用。\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# SIFT 算法\n",
    "\n",
    "SIFT（Scale-Invariant Feature Transform，尺度不变特征变换）是一种用于图像特征检测和描述的算法，由 David Lowe 于 1999 年提出。SIFT 算法能够在不同尺度和旋转角度下检测到图像中的特征点，并生成独特的特征描述子，广泛应用于图像匹配、目标识别、图像拼接等计算机视觉任务中。\n",
    "\n",
    "## 算法步骤\n",
    "\n",
    "SIFT 算法主要分为以下四个步骤：\n",
    "\n",
    "### 1. 尺度空间极值检测\n",
    "\n",
    "尺度空间极值检测是 SIFT（Scale-Invariant Feature Transform）算法的第一步，旨在检测图像中不同尺度下的关键点。这一步骤通过构建尺度空间，并在尺度空间中寻找极值点，确保检测到的特征点具有尺度不变性。\n",
    "\n",
    "#### 原理\n",
    "\n",
    "##### 尺度空间\n",
    "\n",
    "尺度空间是通过对图像进行高斯模糊处理，生成一系列不同尺度的图像。尺度空间的构建公式如下：\n",
    "\n",
    "$$\n",
    "L(x, y, \\sigma) = G(x, y, \\sigma) * I(x, y)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $L(x, y, \\sigma)$ 是尺度空间中的图像。\n",
    "- $G(x, y, \\sigma)$ 是高斯模糊核，其公式为：\n",
    "  $$\n",
    "  G(x, y, \\sigma) = \\frac{1}{2\\pi\\sigma^2} \\exp\\left(-\\frac{x^2 + y^2}{2\\sigma^2}\\right)\n",
    "  $$\n",
    "- $I(x, y)$ 是输入图像。\n",
    "- $*$ 表示卷积操作。\n",
    "- $\\sigma$ 是尺度参数，表示图像模糊的程度。\n",
    "\n",
    "##### 高斯差分金字塔\n",
    "\n",
    "为了高效地检测尺度空间中的极值点，SIFT 算法使用高斯差分（Difference of Gaussian, DoG）金字塔。高斯差分金字塔通过计算相邻两个高斯模糊图像的差分来近似拉普拉斯算子。公式如下：\n",
    "\n",
    "$$\n",
    "D(x, y, \\sigma) = L(x, y, k\\sigma) - L(x, y, \\sigma)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $D(x, y, \\sigma)$ 是高斯差分图像。\n",
    "- $k$ 是尺度空间的尺度倍数，通常取值为 $\\sqrt{2}$。\n",
    "\n",
    "##### 极值检测\n",
    "\n",
    "在构建好的高斯差分金字塔中，SIFT 算法通过比较每个像素点与其邻域内的其他像素点的值，来检测尺度空间中的局部极值点。具体步骤如下：\n",
    "\n",
    "1. **邻域比较**：对于每个像素点，比较其与相邻的 26 个像素点（当前尺度的 8 个邻居点、上一个尺度的 9 个邻居点和下一个尺度的 9 个邻居点）进行比较。如果该点的值是这些点中的最大值或最小值，则认为该点是一个极值点。\n",
    "\n",
    "2. **初始关键点**：将检测到的极值点作为初始关键点。\n",
    "\n",
    "### 2. 关键点精确定位\n",
    "\n",
    "为了提高关键点的精确性，SIFT 算法对初始关键点进行细化处理。细化过程包括：\n",
    "\n",
    "##### 亚像素精确定位\n",
    "\n",
    "使用三次插值拟合方法，对初始关键点进行亚像素精确定位。公式如下：\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = -H^{-1} \\frac{\\partial D}{\\partial \\mathbf{x}}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{X}$ 是关键点的位置偏移量。\n",
    "- $H$ 是高斯差分图像的 Hessian 矩阵。\n",
    "- $\\frac{\\partial D}{\\partial \\mathbf{x}}$ 是高斯差分图像的梯度向量。\n",
    "\n",
    "##### 去除低对比度点\n",
    "\n",
    "计算精确定位后的极值点的对比度值，如果对比度值低于设定的阈值，则去除该点。公式如下：\n",
    "\n",
    "$$\n",
    "D(\\mathbf{x}) + \\frac{1}{2} \\frac{\\partial D}{\\partial \\mathbf{x}}^T \\mathbf{X} < \\text{Threshold}\n",
    "$$\n",
    "\n",
    "##### 去除边缘响应点\n",
    "\n",
    "对极值点的 Hessian 矩阵进行特征值分析，去除边缘响应较强但不稳定的点。公式如下：\n",
    "\n",
    "$$\n",
    "\\text{Tr}(H)^2 / \\text{Det}(H) < \\left(\\frac{r+1}{r}\\right)^2\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\text{Tr}(H)$ 是 Hessian 矩阵的迹。\n",
    "- $\\text{Det}(H)$ 是 Hessian 矩阵的行列式。\n",
    "- $r$ 是边缘响应的阈值，通常取值为 10。\n",
    "\n",
    "### 3. 方向分配\n",
    "\n",
    "为每个关键点分配一个或多个方向，使得特征具有旋转不变性。具体步骤如下：\n",
    "\n",
    "- **计算梯度方向直方图**：在关键点的邻域内计算图像梯度的方向和幅值，生成方向直方图。\n",
    "- **确定主方向**：选择直方图中的主要峰值作为关键点的主方向。\n",
    "- **分配辅助方向**：对于次要峰值，也可以分配辅助方向，从而在不同方向上生成多个关键点。\n",
    "\n",
    "### 4. 关键点描述子生成\n",
    "\n",
    "为每个关键点生成特征描述子，用于特征匹配。具体步骤如下：\n",
    "\n",
    "- **构建梯度直方图**：在关键点邻域内，构建多个子区域的梯度直方图。\n",
    "- **生成特征向量**：将所有子区域的梯度直方图组合形成一个特征向量，作为关键点的特征描述子。"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# cv2.SIFT_create() 方法介绍\n",
    "\n",
    "`cv2.SIFT_create()` 是 OpenCV 库中用于创建 SIFT（Scale-Invariant Feature Transform）对象的方法。SIFT 是一种经典的特征检测和描述算法，具有尺度不变性和旋转不变性，广泛应用于图像匹配、目标识别、图像拼接等计算机视觉任务中。\n",
    "\n",
    "## 使用方法\n",
    "\n",
    "### 创建 SIFT 对象\n",
    "\n",
    "```python\n",
    "sift = cv2.SIFT_create()\n",
    "```\n",
    "\n",
    "### 检测特征点\n",
    "\n",
    "使用 `detect()` 方法检测图像中的特征点：\n",
    "\n",
    "```python\n",
    "kp = sift.detect(gray, None)\n",
    "```\n",
    "\n",
    "- `gray`：输入的灰度图像。\n",
    "- `None`：可选参数，用于掩膜，默认不使用。\n",
    "\n",
    "### 计算特征描述子\n",
    "\n",
    "使用 `compute()` 方法计算特征点的描述子：\n",
    "\n",
    "```python\n",
    "kp, des = sift.compute(gray, kp)\n",
    "```\n",
    "\n",
    "- `kp`：输入的特征点列表。\n",
    "- `des`：输出的特征描述子矩阵。\n",
    "\n",
    "### 检测和计算特征点及描述子\n",
    "\n",
    "使用 `detectAndCompute()` 方法同时检测特征点并计算描述子：\n",
    "\n",
    "```python\n",
    "kp, des = sift.detectAndCompute(gray, None)\n",
    "```\n",
    "\n",
    "- `gray`：输入的灰度图像。\n",
    "- `None`：可选参数，用于掩膜，默认不使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### opencv SIFT函数"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T07:07:17.710841Z",
     "start_time": "2025-02-15T07:07:17.690891Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# 导入图像并将其转化为灰度图\n",
    "img = cv2.imread('photoOpencv/test_1.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "得到特征点"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T07:08:57.505919Z",
     "start_time": "2025-02-15T07:08:57.410948Z"
    }
   },
   "source": [
    "# 创建一个SIFT对象\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "# 使用sift.detect()方法检测图像中的特征点，并将结果存储在 kp变量中。\n",
    "kp = sift.detect(gray, None)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 关键点（Keypoints）\n",
    "\n",
    "关键点是图像中具有显著特征的点，如角点、边缘等。它们在图像匹配、目标识别等任务中起到重要作用。关键点通常具有以下属性：\n",
    "\n",
    "- **位置**：关键点在图像中的坐标（x, y）。\n",
    "- **尺度**：关键点的检测尺度（在多尺度特征检测算法中）。\n",
    "- **方向**：关键点的主方向，用于实现旋转不变性。\n",
    "- **响应值**：关键点的响应值，表示其显著性。\n",
    "- **类别**：关键点的类别信息（可选）。\n",
    "\n",
    "在 OpenCV 中，关键点通常表示为 `cv2.KeyPoint` 对象。\n"
   ]
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T07:09:19.669391Z",
     "start_time": "2025-02-15T07:09:13.208832Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 6,
   "source": [
    "img = cv2.drawKeypoints(gray, kp, img)\n",
    "\n",
    "cv2.imshow('drawKeypoints', img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "计算特征"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-15T07:09:21.774527Z",
     "start_time": "2025-02-15T07:09:21.671798Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 7,
   "source": "kp, des = sift.compute(gray, kp)"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T07:09:22.535140Z",
     "start_time": "2025-02-15T07:09:22.521140Z"
    }
   },
   "source": [
    "print (np.array(kp).shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6828,)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T07:09:23.738040Z",
     "start_time": "2025-02-15T07:09:23.723037Z"
    }
   },
   "source": [
    "des.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6828, 128)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 特征描述子（Descriptors）\n",
    "\n",
    "特征描述子是用于描述关键点局部区域的向量，通常是一个高维向量。描述子用于表示关键点的局部特征，并用于特征匹配。描述子具有以下特点：\n",
    "\n",
    "- **高维向量**：描述子通常是一个固定长度的高维向量。\n",
    "- **唯一性**：描述子应具有唯一性，以便在不同图像中进行特征匹配。\n",
    "- **鲁棒性**：描述子应具有一定的鲁棒性，能够在噪声、旋转、尺度变化等情况下保持稳定。"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-15T07:09:24.987288Z",
     "start_time": "2025-02-15T07:09:24.980280Z"
    }
   },
   "source": [
    "des[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  21.,   8.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 157.,  31.,   3.,   1.,   0.,   0.,\n",
       "         2.,  63.,  75.,   7.,  20.,  35.,  31.,  74.,  23.,  66.,   0.,\n",
       "         0.,   1.,   3.,   4.,   1.,   0.,   0.,  76.,  15.,  13.,  27.,\n",
       "         8.,   1.,   0.,   2., 157., 112.,  50.,  31.,   2.,   0.,   0.,\n",
       "         9.,  49.,  42., 157., 157.,  12.,   4.,   1.,   5.,   1.,  13.,\n",
       "         7.,  12.,  41.,   5.,   0.,   0., 104.,   8.,   5.,  19.,  53.,\n",
       "         5.,   1.,  21., 157.,  55.,  35.,  90.,  22.,   0.,   0.,  18.,\n",
       "         3.,   6.,  68., 157.,  52.,   0.,   0.,   0.,   7.,  34.,  10.,\n",
       "        10.,  11.,   0.,   2.,   6.,  44.,   9.,   4.,   7.,  19.,   5.,\n",
       "        14.,  26.,  37.,  28.,  32.,  92.,  16.,   2.,   3.,   4.,   0.,\n",
       "         0.,   6.,  92.,  23.,   0.,   0.,   0.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
